{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_keras_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_scikit-Learn_**\n",
    "The scikit-learn library in Python is built upon the SciPy stack for efficient numerical computation. It is a fully featured library for general machine learning and provides many utilities that are useful in the development of deep learning models. Not least:\n",
    "- Evaluation of models using resampling methods like k-fold cross validation.\n",
    "- Efficient search and evaluation of model hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Optimizers_**\n",
    "- An optimizer is one of the two arguments required for compiling a Keras model:\n",
    "- SGD Stochastic gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "# Split Train/Test\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with the Keras Sequential model\n",
    "> https://keras.io/getting-started/sequential-model-guide/\n",
    "> The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API, which allows to build arbitrary graphs of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a simple model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(set(iris.target)), activation='softmax'))\n",
    "\n",
    "# Getting started with the Keras Sequential model\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epoch \n",
    "- epochs means how many times you go through your training set.\n",
    "- Batch: a set of N samples. The samples in a batch are processed independently, in parallel. If training, a batch results in only one update to the model.\n",
    "\n",
    "see in detail on the this link https://keras.io/getting-started/faq/#what-does-sample-batch-epoch-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "epoch = 100\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 622us/step - loss: 0.1680 - acc: 0.9400\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 953us/step - loss: 0.1662 - acc: 0.9500\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 792us/step - loss: 0.1965 - acc: 0.9400\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 918us/step - loss: 0.1745 - acc: 0.9200\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1534 - acc: 0.9300\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 712us/step - loss: 0.1543 - acc: 0.9400\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 913us/step - loss: 0.1861 - acc: 0.9300\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 842us/step - loss: 0.1683 - acc: 0.9400\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 807us/step - loss: 0.2256 - acc: 0.9200\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 973us/step - loss: 0.1424 - acc: 0.9400\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1640 - acc: 0.9200\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1786 - acc: 0.916 - 0s 998us/step - loss: 0.1928 - acc: 0.9200\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 772us/step - loss: 0.1409 - acc: 0.9600\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 722us/step - loss: 0.2125 - acc: 0.9500\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 943us/step - loss: 0.1197 - acc: 0.9700\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 692us/step - loss: 0.1790 - acc: 0.9200\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.1564 - acc: 0.9400\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 772us/step - loss: 0.1060 - acc: 0.9700\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 722us/step - loss: 0.1351 - acc: 0.9700\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 572us/step - loss: 0.1492 - acc: 0.9400\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 522us/step - loss: 0.1956 - acc: 0.9400\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 571us/step - loss: 0.1372 - acc: 0.9500\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 572us/step - loss: 0.1432 - acc: 0.9300\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 511us/step - loss: 0.1392 - acc: 0.9400\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 501us/step - loss: 0.1935 - acc: 0.9200\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 521us/step - loss: 0.1406 - acc: 0.9600\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.1440 - acc: 0.9500\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0895 - acc: 1.000 - 0s 451us/step - loss: 0.1552 - acc: 0.9400\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.1308 - acc: 0.9600\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 506us/step - loss: 0.1005 - acc: 0.9900\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 536us/step - loss: 0.1911 - acc: 0.9500\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.1431 - acc: 0.9500\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 556us/step - loss: 0.1500 - acc: 0.9200\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.1597 - acc: 0.9500\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.1600 - acc: 0.9500\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1572 - acc: 0.9300\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 522us/step - loss: 0.1378 - acc: 0.9700\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2530 - acc: 0.900 - 0s 481us/step - loss: 0.1600 - acc: 0.9100\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 512us/step - loss: 0.2041 - acc: 0.9300\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 471us/step - loss: 0.1536 - acc: 0.9300\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 471us/step - loss: 0.1240 - acc: 0.9500\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 431us/step - loss: 0.0898 - acc: 0.9700\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.0945 - acc: 0.9600\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.0847 - acc: 0.9600\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1355 - acc: 0.9500\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.1689 - acc: 0.9300\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.1234 - acc: 0.9500\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.1398 - acc: 0.9400\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.1556 - acc: 0.9400\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.1679 - acc: 0.9400\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.1369 - acc: 0.9600\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 431us/step - loss: 0.2238 - acc: 0.9100\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1258 - acc: 0.9500\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1611 - acc: 0.9400\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.1064 - acc: 0.9700\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.1254 - acc: 0.9600\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0908 - acc: 0.9700\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1174 - acc: 0.9600\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.1714 - acc: 0.9400\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.2004 - acc: 0.9200\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0879 - acc: 0.9700\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.1474 - acc: 0.9600\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.1037 - acc: 0.9500\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.1374 - acc: 0.9400\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1258 - acc: 0.9600\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0795 - acc: 0.9800\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.1320 - acc: 0.9600\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0844 - acc: 0.9500\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0904 - acc: 0.9800\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1506 - acc: 0.9500\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1020 - acc: 0.9700\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 321us/step - loss: 0.0812 - acc: 0.9700\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 321us/step - loss: 0.0933 - acc: 0.9600\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.1858 - acc: 0.9200\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1065 - acc: 0.9600\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 291us/step - loss: 0.1459 - acc: 0.9400\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1265 - acc: 0.9500\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 281us/step - loss: 0.1170 - acc: 0.9600\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0815 - acc: 0.9700\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.1506 - acc: 0.9600\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 281us/step - loss: 0.1357 - acc: 0.9300\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1036 - acc: 0.9700\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.1387 - acc: 0.9500\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0944 - acc: 0.9700\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.1241 - acc: 0.9700\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0744 - acc: 0.9700\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0793 - acc: 0.9800\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.1075 - acc: 0.9800\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.1140 - acc: 0.9700\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3990 - acc: 0.900 - 0s 331us/step - loss: 0.1187 - acc: 0.9700\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.1369 - acc: 0.9500\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0889 - acc: 0.9700\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.1162 - acc: 0.9600\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.0889 - acc: 0.9700\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.1073 - acc: 0.9800\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1095 - acc: 0.9900\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.0857 - acc: 0.9800\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.1255 - acc: 0.9500\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1315 - acc: 0.9200\n",
      "50/50 [==============================] - 0s 291us/step\n",
      "\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "one_hot_label_y_train = np_utils.to_categorical(y_train)\n",
    "one_hot_label_y_test = np_utils.to_categorical(y_test)\n",
    "model.fit(x_train, one_hot_label_y_train, epochs=epoch, batch_size=batch_size)\n",
    "score = model.evaluate(x_test, one_hot_label_y_test, batch_size=batch_size)\n",
    "print(\"\\n{}: {:.2f}%\".format(model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: versicolor,\n",
      "Actual: setosa,\n",
      "Is it Correct: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_data = np.array([4., 3., 4., 1.2])\n",
    "x = predict_data.reshape(-1,4)\n",
    "predict = model.predict(x)\n",
    "\n",
    "for i in range(len(predict)):    \n",
    "    guess = iris.target_names[np.argmax(predict[i])]\n",
    "    actual = iris.target_names[y_train[i]]\n",
    "    print(\"Predict: {},\\nActual: {},\\nIs it Correct: {}\\n\".format(guess, actual, guess==actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
